@misc{https://doi.org/10.48550/arxiv.2206.06761,
  doi = {10.48550/ARXIV.2206.06761},
  url = {https://arxiv.org/abs/2206.06761},
  author = {Rando, Javier and Naimi, Nasib and Baumann, Thomas and Mathys, Max},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Exploring Adversarial Attacks and Defenses in Vision Transformers trained with DINO},
  publisher = {arXiv},
  year = {2022},
  abstract={This work conducts the first analysis on the robustness against adversarial attacks on self-supervised
Vision Transformers trained using DINO. First,
we evaluate whether features learned through selfsupervision are more robust to adversarial attacks
than those emerging from supervised learning.
Then, we present properties arising for attacks
in the latent space. Finally, we evaluate whether
three well-known defense strategies can increase
adversarial robustness in downstream tasks by
only fine-tuning the classification head to provide
robustness even in view of limited compute resources. These defense strategies are: Adversarial
Training, Ensemble Adversarial Training and Ensemble of Specialized Networks.}
  abbr={ICML},
  code={https://github.com/thobauma/AADefDINO},
  arxiv={https://arxiv.org/abs/2206.06761},
  pdf={},
  poster={},
  copyright = {Creative Commons Attribution 4.0 International}
}
